{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split Creation\n",
    "\n",
    "This notebook creates data splits used to evaluate gRNAde on a set of RNA structures of interest from the PDB identified by [Das et al. (2011)](https://www.nature.com/articles/nmeth.1433), which mainly includes riboswitches, aptamers, and ribozymes.\n",
    "When benchmarking gRNAde vs. Rosetta, the training and validation data for the gRNAde model explicitly excluded these RNAsas well as any structurally similar RNAs with TM-score threshold of 0.45 (we used US-align for clustering).\n",
    "Thus, we tried to ensure that gRNAde has not memorized the evaluation dataset for fair comparison.\n",
    "\n",
    "**Workflow:**\n",
    "1. Cluster RNA sample sequences into groups based on structural similarity -- qTMclust for efficiently applying US-align with similarity threshold 0.45.\n",
    "2. Order the clusters based on a metric (median intra-sequence RMSD among available structures within the cluster).\n",
    "3. Identify the clusters belonging to RNAs identified in the Das et al. (2011) paper.\n",
    "4. Add all the selected RNAs as well as all other RNAs in the corresponding clusters to the test set (~100 samples).\n",
    "5. Training and validation splits are semi-randomly split based on the remaining RNAs. Very large (> 1000 nts) RNAs are added to the training set. Validation set RNAs would only come from clusters with less than 5 unique sequences/samples.\n",
    "4. If any samples were not assigned clusters, append them to the training set.\n",
    "\n",
    "Note that we separate very large RNA samples (> 1000 nts) from clustering and directly add these to the training set, as it is unlikely that we want to redesign very large RNAs. We do not process very short RNA samples (< 10 nts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\"/home/ckj24/rna-inverse-folding/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.environ.get(\"DATA_PATH\")\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_to_data = torch.load(os.path.join(DATA_PATH, \"processed.pt\"))\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, \"processed_df.csv\"))\n",
    "# df[\"cluster_structsim0.45\"] = df[\"cluster_structsim0.45\"].fillna(-1)\n",
    "# df[\"cluster_seqid0.8\"] = df[\"cluster_seqid0.8\"].fillna(-1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das_list = [\n",
    "    \"1CSL\", # RRE high affinity site\n",
    "    \"1ET4\", # Vitamin B12 binding RNA aptamer\n",
    "    \"1F27\", # Biotin-binding RNA pseudoknot\n",
    "    \"1L2X\", # Viral RNA pseudoknot\n",
    "    \"1LNT\", # RNA internal loop of SRP\n",
    "    \"1Q9A\", # Sarcin/ricin domain from E.coli 23S rRNA\n",
    "    \"4FE5\", # Guanine riboswitch aptamer (\"1U8D\" is now obsolete, replaced by 4FE5)\n",
    "    \"1X9C\", # All-RNA hairpin ribozyme\n",
    "    \"1XPE\", # HIV-1 B RNA dimerization initiation site\n",
    "    \"2GCS\", # Pre-cleavage state of glmS ribozyme\n",
    "    \"2GDI\", # Thiamine pyrophosphate-specific riboswitch\n",
    "    \"2OEU\", # Junctionless hairpin ribozyme\n",
    "    \"2R8S\", # Synthetic FAB bound to ribozyme domain\n",
    "    \"354D\", # Loop E from E. coli 5S rRNA\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "len(df[\"cluster_structsim0.45\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das_list_to_test_idx = {}\n",
    "\n",
    "for test_idx, idx in enumerate(test_idx_list):\n",
    "    data = list(seq_to_data.values())[idx]\n",
    "    for id in data[\"id_list\"]:\n",
    "        if id.split(\"_\")[0] in das_list:\n",
    "            das_list_to_test_idx[id.split(\"_\")[0]] = test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das_list_to_test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_seq_idx_list = {}     # cluster -> list of seq idx in seq_to_data dict\n",
    "excluded_idx = []                # indexes which will be excluded from val/test set\n",
    "\n",
    "das_list_to_cluster = {}      # ID is Das list -> cluster ID\n",
    "\n",
    "unclustered_id = int(df[\"cluster_structsim0.45\"].max()) + 1  # some clusters were not assigned\n",
    "\n",
    "for seq_idx, data in enumerate(tqdm(seq_to_data.values())):\n",
    "    # exclude very long sequences which are generally ribosomal RNAs\n",
    "    if len(data[\"sequence\"]) > 1000:\n",
    "        excluded_idx.append(seq_idx)\n",
    "    \n",
    "    else:\n",
    "        cluster = int(data[\"cluster_structsim0.45\"])\n",
    "        if cluster == -1:\n",
    "            # assign unclustered sequences to a new cluster\n",
    "            cluster = unclustered_id\n",
    "            unclustered_id += 1\n",
    "\n",
    "        if cluster not in cluster_to_seq_idx_list:\n",
    "            cluster_to_seq_idx_list[cluster] = []\n",
    "        cluster_to_seq_idx_list[cluster].append(seq_idx)\n",
    "\n",
    "        for id in data[\"id_list\"]:\n",
    "            if id.split(\"_\")[0] in das_list:\n",
    "                das_list_to_cluster[id.split(\"_\")[0]] = cluster\n",
    "\n",
    "print(f\"Number of excluded sequences (> 1000 nts): {len(excluded_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das_list_to_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sizes: number of sequences in each cluster\n",
    "cluster_ids = list(cluster_to_seq_idx_list.keys())\n",
    "cluster_sizes = [len(list) for list in cluster_to_seq_idx_list.values()]\n",
    "\n",
    "# Median RMSD for each cluster (in same order as cluster_id list)\n",
    "cluster_median_rmsds = []\n",
    "for cluster, seq_idx_list in cluster_to_seq_idx_list.items():\n",
    "    rmsds = []\n",
    "    for seq_idx in seq_idx_list:\n",
    "        sequence = list(seq_to_data.keys())[seq_idx]  # ugh, how longwinded...\n",
    "        _rmsds = list(seq_to_data[sequence][\"rmsds_list\"].values())\n",
    "        if len(_rmsds) > 0:\n",
    "            rmsds += _rmsds\n",
    "    if len(rmsds) > 0:\n",
    "        cluster_median_rmsds.append(np.median(rmsds))\n",
    "    else:\n",
    "        cluster_median_rmsds.append(0.0)\n",
    "\n",
    "df_split = pd.DataFrame({\n",
    "    'Cluster ID': cluster_ids,\n",
    "    'Cluster size': cluster_sizes,\n",
    "    'Median intra-sequence RMSD': cluster_median_rmsds,\n",
    "})\n",
    "# Sort df_split by median intra-sequence RMSD\n",
    "# df_split = df_split.sort_values(by=\"Median intra-sequence RMSD\", ascending=False)\n",
    "df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split.loc[df_split[\"Cluster ID\"].isin(das_list_to_cluster.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das split preparation\n",
    "\n",
    "# Initialize lists for test, validation, and training set indexes\n",
    "test_idx_list = []\n",
    "val_idx_list = []\n",
    "train_idx_list = []\n",
    "\n",
    "# Training, validation, and test splits become progressively harder.\n",
    "#     - All sequences from Das list as well as those in the same cluster -- test set.\n",
    "#     - All remaining samples -- randomly added to training or validation set.\n",
    "#     - Very large (> 1000 nts) RNAs -- training set.\n",
    "\n",
    "for _, (cluster, cluster_size, median_rmsd) in df_split.iterrows():\n",
    "    seq_idx_list = cluster_to_seq_idx_list[cluster]\n",
    "    assert cluster_size == len(seq_idx_list)\n",
    "\n",
    "    # Test set\n",
    "    if cluster in das_list_to_cluster.values():\n",
    "        test_idx_list += seq_idx_list\n",
    "\n",
    "    # Validation set\n",
    "    elif len(val_idx_list) < 100 and cluster_size < 3:\n",
    "        val_idx_list += seq_idx_list\n",
    "    \n",
    "    # Training set\n",
    "    else:\n",
    "        train_idx_list += seq_idx_list\n",
    "\n",
    "# Add all the sequences that were not assigned any clusters into the training set\n",
    "try:\n",
    "    assert len(test_idx_list) + len(val_idx_list) + len(train_idx_list) == len(list(seq_to_data.keys()))\n",
    "except:\n",
    "    train_idx_list += excluded_idx\n",
    "    assert len(test_idx_list) + len(val_idx_list) + len(train_idx_list) == len(list(seq_to_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RMSD split\n",
    "torch.save(\n",
    "    (train_idx_list, val_idx_list, test_idx_list), \n",
    "    os.path.join(DATA_PATH, \"das_split.pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"split\"] = \"train\"\n",
    "df.loc[val_idx_list, \"split\"] = \"val\"\n",
    "df.loc[test_idx_list, \"split\"] = \"test\"\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"Split: {split}\")\n",
    "    print(f\"Average median RMSD: {df.loc[df.split == split]['median_rmsd'].mean():.2f} +- {df.loc[df.split == split]['median_rmsd'].std():.2f}\")\n",
    "    print(f\"Median number of structures: {df.loc[df.split == split]['num_structures'].median():.2f}\")\n",
    "    df.loc[df.split == split].hist(column=[\"length\", \"num_structures\", \"mean_rmsd\", \"median_rmsd\"], figsize=(10, 10), bins=100)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

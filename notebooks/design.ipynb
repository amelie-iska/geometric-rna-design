{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’£ gRNAde Design Notebook\n",
    "\n",
    "**gRNAde**: **G**eometric Deep Learning pipeline for 3D **RNA** inverse **de**sign. \n",
    "This notebook provides the following functionality: \n",
    "- Full functional usage of pre-trained gRNAde models for fixed backbone re-design of RNA structures from PDB files, such as riboswitches, aptamers, and ribozymes.\n",
    "- Single-state and multi-state design, as well as partial design where key nucleotides are fixed.\n",
    "- Evaluation and visualization tools for designed RNA sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set up the environment\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "from src.data.featurizer import RNAGraphFeaturizer\n",
    "from src.models import AutoregressiveMultiGNNv1\n",
    "from src.trainer import self_consistency_score, self_consistency_score_ribonanza\n",
    "from src.data.sec_struct_utils import predict_sec_struct\n",
    "from src.data.data_utils import edit_distance\n",
    "from src.data.viz_utlils import print_rna_data, draw_struct\n",
    "from src.constants import NUM_TO_LETTER\n",
    "\n",
    "from gRNAde import CHECKPOINT_PATH, set_seed\n",
    "\n",
    "from tools.ribonanzanet.network import RibonanzaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Design scenario\n",
    "##################\n",
    "\n",
    "# Single state or multi state design?\n",
    "# - 1: single state\n",
    "# - 2, 3, 5: multi state (number of states)\n",
    "max_num_conformers = 1\n",
    "\n",
    "# Model checkpoint split:\n",
    "# - options include 'all', 'das', 'multi'\n",
    "# - unless benchmarking, we recommend using 'all' for general usage\n",
    "split = 'all'\n",
    "\n",
    "# random seed for reproducibility\n",
    "seed = 0\n",
    "\n",
    "# Default model hyperparameters (do not change)\n",
    "VERSION = 0.2\n",
    "RADIUS = 0.0\n",
    "TOP_K = 32\n",
    "NUM_RBF = 32\n",
    "NUM_POSENC = 32\n",
    "NOISE_SCALE = 0.1\n",
    "NODE_IN_DIM = (15, 4)\n",
    "NODE_H_DIM = (128, 16)\n",
    "EDGE_IN_DIM = (131, 3)\n",
    "EDGE_H_DIM = (64, 4)\n",
    "NUM_LAYERS = 4\n",
    "DROP_RATE = 0.5\n",
    "OUT_DIM = 4\n",
    "DEFAULT_N_SAMPLES = 16\n",
    "DEFAULT_TEMPERATURE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Initialise gRNAde model and featurizer\n",
    "#########################################\n",
    "\n",
    "# Set random seed\n",
    "set_seed(seed)\n",
    "\n",
    "# Set device (GPU/CPU)\n",
    "device = torch.device(\"cuda:{}\".format(0) if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define data featurizer\n",
    "print(f\"Creating RNA graph featurizer for max_num_conformers={max_num_conformers}\")\n",
    "featurizer = RNAGraphFeaturizer(\n",
    "    split = \"test\",  # set to 'train' to use noise augmentation\n",
    "    radius = RADIUS,\n",
    "    top_k = TOP_K,\n",
    "    num_rbf = NUM_RBF,\n",
    "    num_posenc = NUM_POSENC,\n",
    "    max_num_conformers = max_num_conformers,\n",
    "    noise_scale = NOISE_SCALE\n",
    ")\n",
    "# nucleotide mapping: {'A': 0, 'G': 1, 'C': 2, 'U': 3}\n",
    "\n",
    "# Initialise model\n",
    "print(f\"Initialising GNN encoder-decoder model\")\n",
    "model = AutoregressiveMultiGNNv1(\n",
    "    node_in_dim = NODE_IN_DIM,\n",
    "    node_h_dim = NODE_H_DIM, \n",
    "    edge_in_dim = EDGE_IN_DIM,\n",
    "    edge_h_dim = EDGE_H_DIM, \n",
    "    num_layers = NUM_LAYERS,\n",
    "    drop_rate = DROP_RATE,\n",
    "    out_dim = OUT_DIM\n",
    ")\n",
    "# Load model checkpoint\n",
    "model_path = CHECKPOINT_PATH[split][max_num_conformers]\n",
    "print(f\"Loading gRNAde checkpoint: {model_path}\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "# Transfer model to device in eval mode\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Initialise RibonanzaNet for self-consistency score\n",
    "ribonanza_net = RibonanzaNet(\n",
    "    '/home/ckj24/rna-inverse-folding/tools/ribonanzanet/config.yaml',\n",
    "    '/home/ckj24/rna-inverse-folding/tools/ribonanzanet/ribonanzanet.pt',\n",
    "    device\n",
    ")\n",
    "# Transfer model to device in eval mode\n",
    "ribonanza_net = ribonanza_net.to(device)\n",
    "ribonanza_net.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Load PDB file and featurize\n",
    "##############################\n",
    "\n",
    "pdb_filepath = \"/home/ckj24/rna-inverse-folding/tutorial/demo_data/adenine_riboswitch/5E54_1_B.pdb\"\n",
    "\n",
    "featurized_data, raw_data = featurizer.featurize_from_pdb_file(pdb_filepath)\n",
    "# for multi-state design, use: featurize_from_pdb_filelist\n",
    "\n",
    "# Add predicted secondary structure using EternaFold\n",
    "raw_data['eterna_sec_struct_list'] = predict_sec_struct(raw_data['sequence'])\n",
    "\n",
    "# Add predicted chemical modifications using RibonanzaNet\n",
    "raw_data['ribonanza_chem_mod'] = ribonanza_net.predict(raw_data['sequence'])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "plt.title('Biotite Secondary Structure')\n",
    "draw_struct(raw_data['sequence'], raw_data['sec_struct_list'][0], ax=ax1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "plt.title('EternaFold Predicted Sec. Struct.')\n",
    "draw_struct(raw_data['sequence'], raw_data['eterna_sec_struct_list'][0], ax=ax2)\n",
    "plt.show()\n",
    "\n",
    "print_rna_data(raw_data)\n",
    "\n",
    "print(\"Featurized PyG Data object:\\n\\t\", featurized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Partial sequence constraints\n",
    "###############################\n",
    "\n",
    "print(\"Raw sequence:        \", raw_data['sequence'])\n",
    "print(\"Featurized sequence: \", \"\".join([featurizer.num_to_letter[num] for num in featurized_data.seq.cpu().numpy()]))\n",
    "# Sometimes, the first nucleotide is not included in the featurized sequence due to missing Phosphate coordinates.\n",
    "# In this case, we can add the first nucleotide manually back to designed sequences with very minor post processing.\n",
    "\n",
    "# Set partial sequence constraints (all _'s are designable positions)\n",
    "partial_seq = \"\".join([\"_\"]*len(featurized_data.seq))\n",
    "print(f\"Partial sequence:    \", partial_seq)\n",
    "\n",
    "# Add sequence constraints to partial_seq here:\n",
    "# For instance, we may want to fix key base pairs based on the secondary structure\n",
    "# sequence:    GGGAAGAUAUAAUCCUAAUGAUAUGGUUUGGGAGUUUCUACCAAGAGCCUUAAACUCUUGAUUAUCUU\n",
    "# sec.struct.: ...((((((.(.(((((((.......)))))))((....))((((((.......)))))).)))))))\n",
    "partial_seq = '__________________U_______U______GU____AC_____G_______C_____________'\n",
    "print(f\"Partial sequence:    \", partial_seq)\n",
    "print(f\"Edit distance after fixing positions: {edit_distance(raw_data['sequence'], partial_seq)}\")\n",
    "\n",
    "# transfer data to device\n",
    "featurized_data = featurized_data.to(device)\n",
    "\n",
    "# create logit bias matrix if partial sequence is provided\n",
    "if partial_seq is not None:\n",
    "    # convert partial sequence to tensor\n",
    "    _partial_seq = []\n",
    "    for residue in partial_seq:\n",
    "        if residue in featurizer.letter_to_num.keys():\n",
    "            # fixed nucleotide\n",
    "            _partial_seq.append(featurizer.letter_to_num[residue])\n",
    "        else:\n",
    "            # designable position\n",
    "            _partial_seq.append(len(featurizer.letter_to_num.keys()))\n",
    "    _partial_seq = torch.as_tensor(_partial_seq, device=device, dtype=torch.long)\n",
    "    # convert to one-hot and create bias matrix used during sampling\n",
    "    logit_bias = F.one_hot(_partial_seq, num_classes=model.out_dim+1).float()\n",
    "    \n",
    "    #########################################################\n",
    "    # Create final logit_bias matrix for masked sampling\n",
    "    # - you can manually adjust the bias for more customised \n",
    "    #   designs and constraints. \n",
    "    #########################################################\n",
    "    logit_bias = logit_bias[:, :-1] * 100.0\n",
    "else:\n",
    "    logit_bias = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Sequence design and scoring\n",
    "##############################\n",
    "\n",
    "# Number of designed samples\n",
    "n_samples = 8\n",
    "\n",
    "# Sampling temperature\n",
    "# - Low temperature (eg. 0.1) : more greedy sampling, generally higher sequence recovery\n",
    "# - High temperature (eg. 1.0) : more diverse sampling, generally lower sequence recovery\n",
    "temperature = 0.5\n",
    "\n",
    "# sample n_samples from model for single data point: n_samples x seq_len\n",
    "samples, logits = model.sample(\n",
    "    featurized_data, n_samples, temperature, logit_bias, return_logits=True)\n",
    "\n",
    "# perplexity per sample: n_samples x 1\n",
    "n_nodes = logits.shape[1]\n",
    "perplexity = torch.exp(F.cross_entropy(\n",
    "    logits.view(n_samples * n_nodes, model.out_dim), \n",
    "    samples.view(n_samples * n_nodes).long(), \n",
    "    reduction=\"none\"\n",
    ").view(n_samples, n_nodes).mean(dim=1)).cpu().numpy()\n",
    "\n",
    "# sequence recovery per sample: n_samples x 1\n",
    "recovery = samples.eq(featurized_data.seq).float().mean(dim=1).cpu().numpy()\n",
    "\n",
    "# global self consistency score (EternaFold) per sample: n_samples x 1\n",
    "sc_score, pred_sec_structs = self_consistency_score(\n",
    "    samples.cpu().numpy(), \n",
    "    raw_data['sec_struct_list'], \n",
    "    featurized_data.mask_coords.cpu().numpy(), # np.array([True] * len(raw_data['sequence']))\n",
    "    return_sec_structs = True\n",
    ")\n",
    "\n",
    "# global self consistency score (RibonanzaNet) per sample: n_samples x 1\n",
    "sc_score_ribonanza, pred_chem_mods = self_consistency_score_ribonanza(\n",
    "    samples.cpu().numpy(), \n",
    "    raw_data[\"ribonanza_chem_mod\"].unsqueeze(0).cpu().numpy(), \n",
    "    ribonanza_net,\n",
    "    return_chem_mods = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Visualise and select best designs\n",
    "####################################\n",
    "\n",
    "# collate designed sequences in fasta format\n",
    "sequences = [\n",
    "    # first record: input sequence and model metadata\n",
    "    SeqRecord(\n",
    "        Seq(raw_data[\"sequence\"]),\n",
    "        id=f\"input_sequence,\",\n",
    "        description=f\"checkpoint={model_path}, seed={seed}\"\n",
    "    )\n",
    "]\n",
    "# remaining records: designed sequences and metrics\n",
    "for idx, zipped in enumerate(zip(\n",
    "    samples.cpu().numpy(),\n",
    "    perplexity,\n",
    "    recovery,\n",
    "    sc_score,\n",
    "    pred_sec_structs,\n",
    "    sc_score_ribonanza,\n",
    "    pred_chem_mods\n",
    ")):\n",
    "    seq, perp, rec, sc, pred_ss, sc_ribo, pred_cm = zipped\n",
    "    seq = \"\".join([NUM_TO_LETTER[num] for num in seq])\n",
    "    sequences.append(SeqRecord(\n",
    "        Seq(seq), \n",
    "        id=f\"sample={idx},\",\n",
    "        description=f\"{os.path.split(model_path)[-1]} seed={seed} temperature={temperature} perplexity={perp:.4f} recovery={rec:.4f} sc_score={sc:.4f} sc_score_ribo={sc_ribo:.4f}\"\n",
    "    ))\n",
    "\n",
    "    print(sequences[-1].format('fasta'))\n",
    "    print(f\"Sample {idx}\")\n",
    "    print(f\"    Designed sequence:    {seq}\")\n",
    "    print(f\"    Groundtruth sequence: {raw_data['sequence']}\")\n",
    "    print(f\"    Perplexity: {perp:.4f}\")\n",
    "    print(f\"    Recovery: {rec:.4f}\")\n",
    "    print(f\"    Edit distance: {edit_distance(seq, raw_data['sequence'])}\")\n",
    "    print()\n",
    "    print(f\"    Predicted secondary structure:   {pred_ss[0]}\")\n",
    "    print(f\"    Groundtruth secondary structure: {raw_data['sec_struct_list'][0]}\")\n",
    "    print(f\"    SC Score (EternaFold): {sc:.4f}\")\n",
    "    print(f\"    SC Score (RibonanzaNet): {sc_ribo:.4f}\")\n",
    "    \n",
    "    # create two subplots for predicted and groundtruth secondary structure\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    plt.title('Groundtruth Secondary Structure')\n",
    "    draw_struct(raw_data['sequence'], raw_data['sec_struct_list'][0], ax=ax1)\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    plt.title('Predicted Secondary Structure')\n",
    "    draw_struct(seq, pred_ss[0], ax=ax2)\n",
    "    plt.show()\n",
    "\n",
    "    # plot predicted and groundtruth chemical modification\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('RibonanzaNet Predicted Chemical Modifications')\n",
    "    df = pd.DataFrame({\n",
    "        \"Position\": np.concatenate([np.arange(len(raw_data['sequence']))]*4),\n",
    "        \"Reactivity\": np.concatenate([\n",
    "            raw_data[\"ribonanza_chem_mod\"][:,0].cpu().numpy(), \n",
    "            raw_data[\"ribonanza_chem_mod\"][:,1].cpu().numpy(), \n",
    "            pred_cm[:,0].cpu().numpy(),\n",
    "            pred_cm[:,1].cpu().numpy(),\n",
    "        ]),\n",
    "        \"Source\": np.concatenate([\n",
    "            [\"Groundtruth Sequence\"]*len(raw_data[\"ribonanza_chem_mod\"])*2, \n",
    "            [\"Designed Sequence\"]*len(pred_cm)*2,\n",
    "        ]),\n",
    "        \"Type\": np.concatenate([\n",
    "            [\"2A3\"]*len(raw_data[\"ribonanza_chem_mod\"]),\n",
    "            [\"DMS\"]*len(raw_data[\"ribonanza_chem_mod\"]), \n",
    "            [\"2A3\"]*len(pred_cm),\n",
    "            [\"DMS\"]*len(pred_cm),\n",
    "        ])\n",
    "    })\n",
    "    sns.lineplot(data=df, x=\"Position\", y=\"Reactivity\", hue=\"Type\", style=\"Source\")\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"_\"*150)\n",
    "\n",
    "# write sequences to output filepath\n",
    "# output_filepath = \"\"\n",
    "# SeqIO.write(sequences, output_filepath, \"fasta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
